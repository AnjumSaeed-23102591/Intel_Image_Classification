{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vcPZZbxmSXTu"
   },
   "source": [
    "# **Setup and Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "YAna47wwRcSu"
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tensorflow'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mseaborn\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msns\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mimage\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ImageDataGenerator\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapplications\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ResNet50\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "sns.set(style=\"whitegrid\", palette=\"colorblind\", font_scale=1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2QS2UFNvSbVX"
   },
   "source": [
    "# **Google Drive**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uhSdV8GSSTiY",
    "outputId": "3b127cd2-4698-426e-910d-f332ce5d1712"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KPfFvSClEUsO",
    "outputId": "900fbec8-5ce4-456e-ed0d-b419f38abc55"
   },
   "outputs": [],
   "source": [
    "!ls \"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nHO0kvymDHxv"
   },
   "source": [
    "# **Load and Explore the Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 510
    },
    "id": "6o0mZgc4DKws",
    "outputId": "54598e24-01c4-48cb-f262-39f07eedd5fe"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "#Train Path\n",
    "train_path = \"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\"\n",
    "\n",
    "def explore_dataset(train_dir, output_path=\"class_distribution.png\"):\n",
    "    class_counts = {}\n",
    "    class_labels = []\n",
    "\n",
    "    for class_name in sorted(os.listdir(train_dir)):\n",
    "        class_path = os.path.join(train_dir, class_name)\n",
    "        if os.path.isdir(class_path) and not class_name.startswith(\".\"):\n",
    "            image_files = [f for f in os.listdir(class_path) if f.lower().endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "            count = len(image_files)\n",
    "            if count > 0:\n",
    "                class_counts[class_name] = count\n",
    "                class_labels.append(class_name)\n",
    "\n",
    "    # Plot class distribution\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.barplot(x=list(class_counts.keys()), y=list(class_counts.values()))\n",
    "    plt.title(\"Number of Training Images per Class\")\n",
    "    plt.xlabel(\"Class\")\n",
    "    plt.ylabel(\"Image Count\")\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Save the plot\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"üìÅ Class distribution plot saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "    return class_counts\n",
    "\n",
    "# üîÅ Run the function\n",
    "class_counts = explore_dataset(train_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xFRESSjLGQ6X"
   },
   "source": [
    "# **Show Sample Images per Class**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 500
    },
    "id": "qNRsQSBNGSS_",
    "outputId": "e4265cad-4945-4417-fdb0-44bf1bc5ac09"
   },
   "outputs": [],
   "source": [
    "import matplotlib.image as mpimg\n",
    "def show_sample_images(train_dir, output_path=\"sample_images.png\"):\n",
    "    class_names = sorted(os.listdir(train_dir))\n",
    "    class_names = [cls for cls in class_names if not cls.startswith(\".\")]\n",
    "\n",
    "    plt.figure(figsize=(18, 6))\n",
    "\n",
    "    for idx, cls in enumerate(class_names):\n",
    "        img_folder = os.path.join(train_dir, cls)\n",
    "        img_file = random.choice([\n",
    "            f for f in os.listdir(img_folder)\n",
    "            if f.lower().endswith(('.jpg', '.jpeg', '.png'))\n",
    "        ])\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        img = mpimg.imread(img_path)\n",
    "\n",
    "        plt.subplot(1, len(class_names), idx + 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(cls, fontsize=12)\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Random Sample Image from Each Class\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"Sample image grid saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Use the correct path\n",
    "show_sample_images(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DI_zyWlOHSb2"
   },
   "source": [
    "# **Rotation Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "JaqUPvlCHUcI",
    "outputId": "6292f90f-9e5e-406f-d1ba-cb3bf33873de"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import os\n",
    "import random\n",
    "\n",
    "def preview_rotation_augmentation(data_dir, target_size=(224, 224), num_images=6, output_path=\"aug_rotation.png\"):\n",
    "    datagen = ImageDataGenerator(rotation_range=40)\n",
    "\n",
    "    # Get class folders\n",
    "    class_folders = [d for d in os.listdir(data_dir) if not d.startswith(\".\")]\n",
    "    sample_images = []\n",
    "\n",
    "    # Pick random images from random classes\n",
    "    for _ in range(num_images):\n",
    "        class_choice = random.choice(class_folders)\n",
    "        img_folder = os.path.join(data_dir, class_choice)\n",
    "        img_file = random.choice([f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        sample_images.append((img_path, class_choice))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i, (img_path, label) in enumerate(sample_images):\n",
    "        # Load and preprocess\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        # Generate rotated image\n",
    "        aug_iter = datagen.flow(img_array, batch_size=1)\n",
    "        rotated_img = next(aug_iter)[0].astype(\"uint8\")\n",
    "\n",
    "        # Plot original\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(img_array[0].astype(\"uint8\"))\n",
    "        plt.title(f\"Original\\n{label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Plot rotated\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(rotated_img)\n",
    "        plt.title(f\"Rotated\\n{label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Rotation Augmentation Preview\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"‚úÖ Rotation augmentation saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# üîÅ Run it\n",
    "preview_rotation_augmentation(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rDn3LersIHOT"
   },
   "source": [
    "# **CLAHE Contrast Enhancement**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "MumEdS_ZIJ7V",
    "outputId": "2fe54f14-2074-4a52-af28-501710065cc2"
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import os\n",
    "\n",
    "def apply_clahe(image_path, tile_grid_size=(8, 8), clip_limit=2.0):\n",
    "    img = cv2.imread(image_path)  # BGR format\n",
    "    lab = cv2.cvtColor(img, cv2.COLOR_BGR2LAB)\n",
    "    l, a, b = cv2.split(lab)\n",
    "\n",
    "    clahe = cv2.createCLAHE(clipLimit=clip_limit, tileGridSize=tile_grid_size)\n",
    "    cl = clahe.apply(l)\n",
    "\n",
    "    limg = cv2.merge((cl, a, b))\n",
    "    final = cv2.cvtColor(limg, cv2.COLOR_LAB2RGB)  # convert to RGB for display\n",
    "    original_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    return original_rgb, final\n",
    "\n",
    "def preview_clahe_augmentation(data_dir, num_images=6, output_path=\"aug_clahe.png\"):\n",
    "    class_folders = [d for d in os.listdir(data_dir) if not d.startswith(\".\")]\n",
    "    sample_images = []\n",
    "\n",
    "    for _ in range(num_images):\n",
    "        class_choice = random.choice(class_folders)\n",
    "        img_folder = os.path.join(data_dir, class_choice)\n",
    "        img_file = random.choice([f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        sample_images.append((img_path, class_choice))\n",
    "\n",
    "    # Plot\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i, (img_path, label) in enumerate(sample_images):\n",
    "        orig, enhanced = apply_clahe(img_path)\n",
    "\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(orig)\n",
    "        plt.title(f\"Original\\n{label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(enhanced)\n",
    "        plt.title(f\"CLAHE\\n{label}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"CLAHE Contrast Enhancement Preview\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"‚úÖ CLAHE augmentation saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# üîÅ Run it\n",
    "preview_clahe_augmentation(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jYcxBW0mIrZq"
   },
   "source": [
    "# **Horizontal Flip Augmentation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "x93Je3NTIp_I",
    "outputId": "c1a7ba42-bcb0-4d64-e74a-5d292c970d71"
   },
   "outputs": [],
   "source": [
    "def preview_horizontal_flip(data_dir, target_size=(224, 224), num_images=6, output_path=\"aug_flip.png\"):\n",
    "    from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "    import matplotlib.pyplot as plt\n",
    "    import numpy as np\n",
    "    import os\n",
    "    import random\n",
    "\n",
    "    datagen = ImageDataGenerator(horizontal_flip=True)\n",
    "\n",
    "    # Force use of 'street' class for clear visual flips\n",
    "    class_choice = \"street\"\n",
    "    img_folder = os.path.join(data_dir, class_choice)\n",
    "    all_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "\n",
    "    # Pick random images only from 'street'\n",
    "    sample_images = random.sample(all_files, num_images)\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i, img_file in enumerate(sample_images):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        flipped_img = next(datagen.flow(img_array_expanded, batch_size=1))[0].astype(\"uint8\")\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(img_array.astype(\"uint8\"))\n",
    "        plt.title(f\"Original\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Flipped\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(flipped_img)\n",
    "        plt.title(f\"Flipped\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Horizontal Flip Augmentation Preview (Street Images)\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"‚úÖ Horizontal flip augmentation saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run it!\n",
    "preview_horizontal_flip(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ej9uoon8K5oV"
   },
   "source": [
    "# **Zoom & Crop Augmentation Preview**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "HFkqBI9OK5Wm",
    "outputId": "1ad7e767-c3a0-49d7-ed17-31569d8d9b8c"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "\n",
    "def preview_zoom_augmentation(data_dir, target_size=(224, 224), num_images=6, output_path=\"aug_zoom.png\"):\n",
    "    datagen = ImageDataGenerator(zoom_range=0.3)  # Zoom in 0‚Äì30%\n",
    "\n",
    "    # Choose a visually rich class (e.g., 'mountain' or 'forest')\n",
    "    class_choice = \"mountain\"\n",
    "    img_folder = os.path.join(data_dir, class_choice)\n",
    "    all_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    sample_images = random.sample(all_files, num_images)\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i, img_file in enumerate(sample_images):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        img = load_img(img_path, target_size=target_size)\n",
    "        img_array = img_to_array(img)\n",
    "        img_array_expanded = np.expand_dims(img_array, axis=0)\n",
    "\n",
    "        zoomed_img = next(datagen.flow(img_array_expanded, batch_size=1))[0].astype(\"uint8\")\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(img_array.astype(\"uint8\"))\n",
    "        plt.title(f\"Original\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Zoomed\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(zoomed_img)\n",
    "        plt.title(f\"Zoomed\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Zoom Augmentation Preview\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"‚úÖ Zoom augmentation saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "preview_zoom_augmentation(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "u2UByizZLWAQ"
   },
   "source": [
    "# **Gaussian Blur**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 772
    },
    "id": "fLGMCqe9LXvP",
    "outputId": "af936255-f86d-4ccf-d9d8-41f6fc1d4a20"
   },
   "outputs": [],
   "source": [
    "def apply_blur(image_path, ksize=(5, 5)):\n",
    "    img = cv2.imread(image_path)\n",
    "    img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    blurred = cv2.GaussianBlur(img_rgb, ksize, 0)\n",
    "    return img_rgb, blurred\n",
    "\n",
    "def preview_blur_augmentation(data_dir, num_images=6, output_path=\"aug_blur.png\"):\n",
    "    class_choice = \"glacier\"  # visually sharp class works well\n",
    "    img_folder = os.path.join(data_dir, class_choice)\n",
    "    all_files = [f for f in os.listdir(img_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
    "    sample_images = random.sample(all_files, num_images)\n",
    "\n",
    "    plt.figure(figsize=(18, 8))\n",
    "    for i, img_file in enumerate(sample_images):\n",
    "        img_path = os.path.join(img_folder, img_file)\n",
    "        original, blurred = apply_blur(img_path)\n",
    "\n",
    "        # Original\n",
    "        plt.subplot(2, num_images, i + 1)\n",
    "        plt.imshow(original)\n",
    "        plt.title(f\"Original\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "        # Blurred\n",
    "        plt.subplot(2, num_images, num_images + i + 1)\n",
    "        plt.imshow(blurred)\n",
    "        plt.title(f\"Blurred\\n{class_choice}\")\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Gaussian Blur Augmentation Preview\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\"‚úÖ Blur augmentation saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Run it\n",
    "preview_blur_augmentation(\"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKqzN6CML2DJ"
   },
   "source": [
    "# **Data Preprocessing Pipeline for Model Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Qzw0vHslL1kZ",
    "outputId": "ac14edf8-613d-4414-ea61-71cd8b755ca0"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Define paths\n",
    "train_dir = \"/content/drive/MyDrive/Colab Notebooks/intel_image_classification/seg_train/seg_train\"\n",
    "\n",
    "# Image size & batch settings\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Augmentations for training set\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    rotation_range=30,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    validation_split=0.2  # 80% train, 20% validation\n",
    ")\n",
    "\n",
    "#  No augmentation for validation, only rescaling\n",
    "val_datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "# Create the generators\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='training',\n",
    "    shuffle=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "val_generator = val_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=IMG_SIZE,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mTKf3NtMMSZ_"
   },
   "source": [
    "# **Visualize Augmented Images from Generator**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 816
    },
    "id": "pGPiYMihMRWn",
    "outputId": "b44a8f03-ba5b-4ab7-dd19-d69785b8913e"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preview_augmented_batch(generator, class_names, output_path=\"batch_preview.png\"):\n",
    "    images, labels = next(generator)  # Get one batch\n",
    "\n",
    "    plt.figure(figsize=(16, 8))\n",
    "    for i in range(8):\n",
    "        plt.subplot(2, 4, i + 1)\n",
    "        plt.imshow(images[i])\n",
    "        label_index = labels[i].argmax()\n",
    "        plt.title(class_names[label_index])\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.suptitle(\"Sample Augmented Images from Training Generator\", fontsize=16)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(output_path)\n",
    "    print(f\" Augmented batch preview saved as: {output_path}\")\n",
    "    plt.show()\n",
    "\n",
    "# Class labels from generator\n",
    "class_names = list(train_generator.class_indices.keys())\n",
    "\n",
    "# üîÅ Run it\n",
    "preview_augmented_batch(train_generator, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sNRReEXsM39i"
   },
   "source": [
    "# **Model Implementation**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYyzA1SwNdNM"
   },
   "source": [
    "**ResNet50 Transfer Learning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "CNosI_qgM2tQ",
    "outputId": "d35ebc17-2d62-4716-8b66-5f1711bcdfc6"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense, Dropout, Input\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "def build_resnet_model(input_shape=(224, 224, 3), num_classes=6, learning_rate=0.0001):\n",
    "    base_model = ResNet50(weights='imagenet', include_top=False, input_tensor=Input(shape=input_shape))\n",
    "    base_model.trainable = False  # Freeze base layers\n",
    "\n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Dense(128, activation='relu')(x)\n",
    "    output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    model = Model(inputs=base_model.input, outputs=output)\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=Adam(learning_rate=learning_rate),\n",
    "        loss='categorical_crossentropy',\n",
    "        metrics=['accuracy']\n",
    "    )\n",
    "\n",
    "    print(\"‚úÖ ResNet50 model built and compiled.\")\n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "resnet_model = build_resnet_model()\n",
    "resnet_model.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rhOYHT-cNoA8"
   },
   "source": [
    "**Train RestNet50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wvAoGTOLNhMr",
    "outputId": "54f3bd14-81fc-4b52-dc53-2d87f030cb29"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_path = \"resnet50_best_model.h5\"\n",
    "\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',\n",
    "    save_best_only=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "early_stop = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    patience=5,\n",
    "    restore_best_weights=True,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# üìä Train the model\n",
    "history = resnet_model.fit(\n",
    "    train_generator,\n",
    "    validation_data=val_generator,\n",
    "    epochs=10,\n",
    "    callbacks=[checkpoint, early_stop],\n",
    "    verbose=1\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
